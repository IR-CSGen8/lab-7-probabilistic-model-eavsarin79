{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c892250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"I love cats . cats are cute pets.\",\n",
    "    \"Dogs are loyal. Dogs are good friends.\",\n",
    "    \"Birds can sing. Birds fly in the sky.\",\n",
    "    \"Fish live underwater. Fish come in many colors.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a685610",
   "metadata": {},
   "source": [
    "In this section, we define and create unigram models for the documents. Unigrams are single words or terms, and a unigram model represents the probability distribution of individual terms in the document. The unigram_model function counts the occurrences of each term in a document, calculates the probabilities, and returns the unigram model. We create unigram models for all documents in the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0e623",
   "metadata": {},
   "source": [
    "# Create Unigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d589155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_model(document):\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    unigram_counts = defaultdict(int)\n",
    "    for word in words:\n",
    "        unigram_counts[word] += 1\n",
    "    unigram_model = {word: count / total_words for word, count in unigram_counts.items()}\n",
    "    return unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c571b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigram models for all documents\n",
    "unigram_models = [unigram_model(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16bdec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'I': 0.125,\n",
       "  'love': 0.125,\n",
       "  'cats': 0.25,\n",
       "  '.': 0.125,\n",
       "  'are': 0.125,\n",
       "  'cute': 0.125,\n",
       "  'pets.': 0.125},\n",
       " {'Dogs': 0.2857142857142857,\n",
       "  'are': 0.2857142857142857,\n",
       "  'loyal.': 0.14285714285714285,\n",
       "  'good': 0.14285714285714285,\n",
       "  'friends.': 0.14285714285714285},\n",
       " {'Birds': 0.25,\n",
       "  'can': 0.125,\n",
       "  'sing.': 0.125,\n",
       "  'fly': 0.125,\n",
       "  'in': 0.125,\n",
       "  'the': 0.125,\n",
       "  'sky.': 0.125},\n",
       " {'Fish': 0.25,\n",
       "  'live': 0.125,\n",
       "  'underwater.': 0.125,\n",
       "  'come': 0.125,\n",
       "  'in': 0.125,\n",
       "  'many': 0.125,\n",
       "  'colors.': 0.125}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa6e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a query \n",
    "query = \"I like cats and dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f84e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_probability(query, document_model):\n",
    "    # Tokenize the query into words\n",
    "    query_words = query.split()\n",
    "    \n",
    "    # Initialize the probability for the entire query\n",
    "    query_probability = 1.0\n",
    "    \n",
    "    # Calculate the probability for each term in the query\n",
    "    for word in query_words:\n",
    "        if word in document_model:\n",
    "            query_probability *= document_model[word]\n",
    "        else:\n",
    "            query_probability = 0.0\n",
    "            break\n",
    "    \n",
    "    return query_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25934062",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_probability = calculate_query_probability(query, unigram_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e57e1768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315f9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6640e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_probabilities\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate the query probabilities for each document using Laplace smoothing\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m query_probabilities \u001b[38;5;241m=\u001b[39m calculate_query_probabilities(query, document_models, smoothing_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Print the query probabilities for each document\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, probability \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(query_probabilities):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document_models' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2641c2c",
   "metadata": {},
   "source": [
    "## Your task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "771db8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Query Probability: 5.208333333333334e-05\n",
      "Document 2 Query Probability: 0.00012860082304526747\n",
      "Document 3 Query Probability: 3.0517578125e-05\n",
      "Document 4 Query Probability: 3.0517578125e-05\n"
     ]
    }
   ],
   "source": [
    "def create_document_models(documents):\n",
    "    document_models = []\n",
    "    \n",
    "    for document in documents:\n",
    "        document_model = {}\n",
    "        words = document.split()\n",
    "        total_words = len(words)\n",
    "        \n",
    "        # Count the frequency of each word in the document\n",
    "        for word in words:\n",
    "            if word in document_model:\n",
    "                document_model[word] += 1\n",
    "            else:\n",
    "                document_model[word] = 1\n",
    "        \n",
    "        # Convert word frequencies to probabilities with Laplace smoothing (no smoothing_factor)\n",
    "        for word in document_model:\n",
    "            document_model[word] = (document_model[word] + 1) / (total_words + len(document_model))\n",
    "        \n",
    "        document_models.append(document_model)\n",
    "    \n",
    "    return document_models\n",
    "\n",
    "def calculate_query_probabilities(query, document_models):\n",
    "    query_probabilities = []\n",
    "    \n",
    "    for document_model in document_models:\n",
    "        query_probability = calculate_query_probability(query, document_model)\n",
    "        query_probabilities.append(query_probability)\n",
    "    \n",
    "    return query_probabilities\n",
    "\n",
    "def calculate_query_probability(query, document_model):\n",
    "    words = query.split()\n",
    "    query_probability = 1.0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in document_model:\n",
    "            query_probability *= document_model[word]\n",
    "        else:\n",
    "            query_probability *= 1.0 / (len(document_model) + 1) \n",
    "        \n",
    "    return query_probability\n",
    "\n",
    "# Create the document models\n",
    "document_models = create_document_models(documents)\n",
    "\n",
    "query_probabilities = calculate_query_probabilities(query, document_models)\n",
    "\n",
    "for i, probability in enumerate(query_probabilities):\n",
    "    print(\"Document\", i+1, \"Query Probability:\", probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2705d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee5e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Laplace-Smoothed Bigram Model:\n",
      "I love: 0.1250\n",
      "love cats: 0.1250\n",
      "cats .: 0.1250\n",
      ". cats: 0.1250\n",
      "cats are: 0.1250\n",
      "are cute: 0.1250\n",
      "cute pets.: 0.1250\n",
      "\n",
      "Document 2 Laplace-Smoothed Bigram Model:\n",
      "Dogs are: 0.2143\n",
      "are loyal.: 0.1429\n",
      "loyal. Dogs: 0.1429\n",
      "are good: 0.1429\n",
      "good friends.: 0.1429\n",
      "\n",
      "Document 3 Laplace-Smoothed Bigram Model:\n",
      "Birds can: 0.1250\n",
      "can sing.: 0.1250\n",
      "sing. Birds: 0.1250\n",
      "Birds fly: 0.1250\n",
      "fly in: 0.1250\n",
      "in the: 0.1250\n",
      "the sky.: 0.1250\n",
      "\n",
      "Document 4 Laplace-Smoothed Bigram Model:\n",
      "Fish live: 0.1250\n",
      "live underwater.: 0.1250\n",
      "underwater. Fish: 0.1250\n",
      "Fish come: 0.1250\n",
      "come in: 0.1250\n",
      "in many: 0.1250\n",
      "many colors.: 0.1250\n",
      "\n",
      "Query Bigram Probabilities for Each Document:\n",
      "Document 1: 0.000026\n",
      "Document 2: 0.000048\n",
      "Document 3: 0.000026\n",
      "Document 4: 0.000026\n",
      "The most probable document for the query is: Dogs are loyal. Dogs are good friends.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate Laplace-smoothed bigram models\n",
    "def laplace_smoothed_bigram_model(document):\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    bigram_counts = defaultdict(int)\n",
    "    \n",
    "    # Initialize all bigrams with a count of 1 (Laplace smoothing)\n",
    "    for i in range(total_words - 1):\n",
    "        bigram = (words[i], words[i + 1])\n",
    "        bigram_counts[bigram] += 1\n",
    "    \n",
    "    # Calculate Laplace-smoothed probabilities\n",
    "    bigram_model = {bigram: (count + 1) / (total_words + total_words) for bigram, count in bigram_counts.items()}\n",
    "    return bigram_model\n",
    "\n",
    "# Create Laplace-smoothed bigram models for all documents\n",
    "laplace_smoothed_bigram_models = [laplace_smoothed_bigram_model(doc) for doc in documents]\n",
    "\n",
    "# Print Laplace-smoothed bigram models\n",
    "for i, model in enumerate(laplace_smoothed_bigram_models):\n",
    "    print(f\"Document {i + 1} Laplace-Smoothed Bigram Model:\")\n",
    "    for bigram, probability in model.items():\n",
    "        print(f\"{bigram[0]} {bigram[1]}: {probability:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Define a query\n",
    "query = \"I like cats and dogs\"\n",
    "\n",
    "def calculate_query_probability(query, document_model):\n",
    "    query_words = query.split()\n",
    "    query_bigrams = [(query_words[i], query_words[i + 1]) for i in range(len(query_words) - 1)]\n",
    "    \n",
    "    query_probability = 1.0\n",
    "    \n",
    "    for bigram in query_bigrams:\n",
    "        # Apply Laplace smoothing for unseen bigrams using the document_model\n",
    "        bigram_probability = document_model.get(bigram, 1 / (len(document_model) + len(laplace_smoothed_bigram_models[0])))\n",
    "        query_probability *= bigram_probability\n",
    "\n",
    "    return query_probability\n",
    "\n",
    "# Calculate query probability for each document\n",
    "query_probabilities = []\n",
    "\n",
    "for document_model in laplace_smoothed_bigram_models:\n",
    "    probability = calculate_query_probability(query, document_model)\n",
    "    query_probabilities.append(probability)\n",
    "\n",
    "# Find the document with the highest probability for the query\n",
    "most_probable_document_index = query_probabilities.index(max(query_probabilities))\n",
    "most_probable_document = documents[most_probable_document_index]\n",
    "\n",
    "print(\"Query Bigram Probabilities for Each Document:\")\n",
    "for i, probability in enumerate(query_probabilities):\n",
    "    print(f\"Document {i + 1}: {probability:.6f}\")\n",
    "\n",
    "print(\"The most probable document for the query is:\", most_probable_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51476aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2e984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f66f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0a011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
